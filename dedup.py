#!/usr/bin/env python2.7
#
# Identify duplicate files to possibly replace with hard links to save space:
#
#     find /Users/boris -type f | ./dedup.py --scan > boris.txt
#     cat boris.txt | ./dedup.py --analyze
#
# The candidate list generated by those steps should be carefully reviewed
# for safety.  For example, any files under version control or subject to
# modification must be left alone, even if they appear to be duplicates.
#

import os
import sys
import threading
import subprocess
from collections import defaultdict


# scan params
XARGS_COUNT = 50
MAX_SUBPROCS = 8

# analysis params
MIN_FILE_SIZE = 256*1024
MIN_DEDUP = 2*1024*1024


ts_lock = threading.RLock()


def tsout(msg):
    with ts_lock:
        sys.stdout.write(str(msg))
        sys.stdout.write("\n")


def tserr(msg, lock=threading.RLock()):
    with ts_lock:
        sys.stderr.write(str(msg))
        sys.stderr.write("\n")


subprocs = threading.Semaphore(MAX_SUBPROCS)


SCAN_RESULTS = []


def process(chunk):
    try:
        md5_command = "/sbin/md5 -r".split() + chunk
        md5_raw_results = subprocess.check_output(md5_command)
        md5_results = []
        for i, line in enumerate(md5_raw_results.split("\n")):
            if not line:
                continue
            md5_hash, file_name = line.lstrip().split(None, 1)
            orig_file_name = chunk[i]
            if file_name != orig_file_name:
                tserr("WARNING: Filename not preserved by md5: before '{}', after '{}'.  Skipping.".format(orig_file_name, file_name))
                continue
            sr = os.stat(orig_file_name)
            r = (md5_hash, sr.st_nlink, sr.st_size, orig_file_name)
            md5_results.append(r)
            tsout("{} {} {} {}".format(*r))
        with ts_lock:
            SCAN_RESULTS.extend(md5_results)
    finally:
        subprocs.release()


def enqueue_scan(chunk):
    subprocs.acquire()
    threading.Thread(target=process, args=[chunk]).start()


def scan():
    tserr("Reading filenames from stdin.")
    line_count = 0
    chunk = []
    for line in sys.stdin:
        assert line
        line_count += 1
        line = line[:-1]
        if len(chunk) == XARGS_COUNT:
            enqueue_scan(chunk)
            chunk = []
        chunk.append(line)
    enqueue_scan(chunk)
    for i in xrange(MAX_SUBPROCS):
        subprocs.acquire()
    tserr("Scanned {} files.".format(len(SCAN_RESULTS)))


class MD5Hash(object):

    def __init__(self):
        self.md5_hash = None
        self.files = []
        self.current_size = 0.0
        self.ideal_size = None

    def add_file(self, md5_hash, n_link, size, file_name):
        assert not self.md5_hash or self.md5_hash == md5_hash
        self.md5_hash = md5_hash
        assert not self.ideal_size or self.ideal_size == size
        self.ideal_size = size
        self.files.append((md5_hash, n_link, size, file_name))
        self.current_size += (float(size) / n_link)

def analyze():
    files = defaultdict(MD5Hash)
    line_count = 0
    eligible_count = 0
    ignored_count = 0
    for line in sys.stdin:
        assert line
        line_count += 1
        line = line[:-1]
        md5_hash, n_link, size, file_name = line.split(None, 3)
        n_link = int(n_link)
        size = int(size)
        if size < MIN_FILE_SIZE:
            ignored_count += 1
            continue
        eligible_count += 1
        files[md5_hash].add_file(md5_hash, n_link, size, file_name)
    tsout("{} files eligible for deduplication = {:3.1f}% of {} total files.".format(eligible_count, 100.0*eligible_count/line_count, line_count))
    tsout("{} duplicates = {:3.1f}% of {} eligible files.".format(eligible_count-len(files), 100.0 - 100.0*len(files)/eligible_count, eligible_count))
    mb = 1024*1024
    ideal = sum(f.ideal_size for f in files.itervalues()) / mb
    current = sum(f.current_size for f in files.itervalues()) / mb
    tsout("space savings {:.0f} MB = {:3.1f}% of {:.0f} MB current size.".format(current - ideal, 100.0 - 100.0*ideal/current, current))
    for md5 in sorted(files.itervalues(), key=lambda f: f.current_size - f.ideal_size):
        if md5.current_size - md5.ideal_size < MIN_DEDUP:
            continue
        tsout("")
        tsout("Save {:.1f} MB by deduping\n{}".format((md5.current_size - md5.ideal_size) / mb, "".join(["\n        " + f[3] for f in md5.files])))
        tsout("")

if __name__ == "__main__":
    if len(sys.argv) >= 2 and sys.argv[1].strip('-').lower() == "scan":
        scan()
    elif len(sys.argv) >= 2 and sys.argv[1].strip('-').lower() in ("analyze", "analyse", "analysis"):
        analyze()
    else:
        tserr("Unsupported command line.")
        sys.exit(-1)
    #tsprint(repr(RESULTS))
